本次作业由唐子康，格根塔娜，覃美萍，吴美听四人完成
其中唐子康是队长


运行本项目需要先运行main.py启动endpoint
再运行web1.py启动web部分
test,pastVersion为测试和debug时写的文件
rdflib-endpiont 文件夹为对应的源码

每个部分的说明分别在对应的文件夹之下
GGNT为格根塔娜负责的部分主要为大作业第一部分和前端的一个界面（html）
QMP为覃美萍负责部分主要是问句解析
WMT为吴美听负责rml规则,将爬取的信息转化为ttl
spider，项目文件夹为唐子康负责包括爬虫endpoint和web网页部分，主要负责这些部分的实现以及调整整体代码的结构和debug
还有本地语言模型的实现，以及再云服务器上的架构

以下是唐子康负责部分的说明文档
爬虫部分：由于需要爬取大量的信息，需要大量的IO操作，为了提升爬虫效率使用了python 的aiohttp等支持异步的库
爬取的时候只需要在命令行里运行spder.py使用>操作符将结果保存在txt文件之中，再使用convert.py将其转化为csv文件
由于爬取的数据部分不符合规律，所以手动对数据进行了修改，根据上一步的需求，主要爬取了针灸学的部分

endpoint的部分首先参考了资料之中的查询，但是发现资料之中的查询并没有实现endpoint，而是将数据放在本地使用rdflib进行查询，
于是找到了库的源码（https://github.com/vemonet/rdflib-endpoint）仔细阅读之后实现了endpoint.py里的endpoint类，库本身是使用FastAPI实现的，目前还没有靠flask启动的情况，参考FastAPI实现了endpoint，其中costom_concat和most_similar部分的代码为官网所给，为了增强搜索的效果（相对于命令行内的启动）
运行的时候运行main.py 再对应的网址内是endpoint的查询界面

web部分使用FastAPI实现，考虑到EndPoint的部分，于是使用FastAPI实现，写了两个界面，其中一个是专门用于查询的，另外一个/index路由下的为格根塔娜完成，负责相关知识的介绍以及简单的查询 ，
web1.py为文件的网页的后端部分

大模型部分参考了https://github.com/2020MEAI/TCMLLM，实现了在服务器端的查询，由于资金有限导致不能够运行在本地，文件较大，就不放在作业里面了。
从创业的角度考虑，自己本地的大模型更适合知识图谱，一方面是通用大模型的回答往往只是对于原有的重复，信息增益不大第二访问其他大模型对于访问是有限制的，往往是响应速度跟不上
可以采用网址的指导复现查询操作

除了以上的部分，完成了对于代码结构的调整，具体可以比较WMT文件夹下面的untitled（1）文件和Query类和QueryTemplates类使用sparqlwrapper 来实现向endpoint实现查询，以及整体代码的调试

